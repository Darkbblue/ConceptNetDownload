# 爬虫控制流
## 概述
### 基本信息
本爬虫用于构建多模态常识知识图谱。  
本爬虫包含文本数据获取、多模态数据获取、辅助功能三个模块。  
本任务属于读写密集型任务，对计算的要求不高，因此选择python多线程设计，并使用threading库实现了一个简单的多阶段线程池以进行任务调度。  
### 用语规定
图谱构建的两个阶段，即从ConceptNet获取文本数据和进行多模态数据扩展，分别被命名为fetch和extend。  
爬虫中直接涉及到控制流的函数分为三类，Monitor负责进行任务分配，会长期执行；Worker的一次调用会完成一个实体或关系的爬取任务；Assist为进度保存、数据传输等辅助功能。  
### 目录结构
- scripts: 在多模态数据接收节点上运行的脚本，会自动化地将分卷压缩包拼接起来、解压缩、数据移动到m文件夹下，然后删除压缩包；注意使用前应保证当前目录下存在一个名称为'm'的子文件夹

- tools: 爬虫组件
	- add.py: 向数据库中添加记录
	- download_gifs.py: 下载动图
	- download_images.py: 下载图片
	- download_sounds: 下载音频
	- extend.py: 进行多模态数据扩展
	- fetch.py: 从ConceptNet中爬取文本数据
	- proxy.py: 提供代理
	- transport.py: 将多模态数据打包传输到本地节点
	- uri.py: 官方提供的工具，目前只用到将uri转换成label的功能

- clear.py: 将数据库中的数据全部清除
- history.py: 查看历史记录的长度，用来检查爬取进度

- **main.py**: 主函数，核心控制流位于此处

- test.py: 杂七杂八的测试
- test_proxy.py: 测试代理是否可用
- test_transport.py: 测试多模态打包传输功能


## 简单的多阶段线程池
### 需求
需要能够方便地控制并发度，从而控制爬取效率，避免被封IP。因此选择线程池机制。  
本爬虫的任务分为fetch和extend两个阶段，因此python的线程池库(threadpoolexecutor)不能很好的实现需求。  
(*现在想了一下好像其实可以*)  
### 实现方式
#### pool
使用一个词典作为池子的物理实现方式，将对应任务的uri作为key，子线程对象本身作为value。  
通过词典的长度，可以方便地获取到当前并发线程数目。  
除记录当前工作中任务的词典外，也使用其他词典对待执行任务和已完成任务进行记录。共计使用to_fetch, on_fetch, to_extend, on_extend, finished五个池。  
#### 任务分配
Monitor类函数负责任务分配。  
这些函数会在启动后进入无限循环，每隔一定时间检查当前并发线程数目，当此数目低于设定的并发度上限时，尝试分配新的任务，直到达到上限或待执行任务耗尽。  
分配任务的方式是以子线程形式调用一个Worker类函数，并且将对应的任务记录从待执行池移动到执行中池。  
若在某时刻，Monitor函数发现不仅待执行任务池已耗尽，并且可以认为不可能再有新任务被添加到其中，则会尝试结束执行。此时，该函数会等待较长的时间，若等待结束后观察结果不变，则结束本函数的执行。  
#### 新任务添加
添加新任务的方式是向待执行池(to_fetch, to_extend)添加新的元素。  
由于Monitor类不方便获得Worker类的返回值，所以添加新任务的工作在Worker类中完成。  
#### 任务完成
出于和上一条类似的原因，在任务完成时，由Worker类自行将自己移出执行中池。  
#### 池间的移动
线程池的实现涉及到不同池之间的元素移动。进行这种移动时，会通过加锁避免冲突。  
#### 异常处理
Worker类中有通用的异常处理机制，若检测到异常抛出，会将当前任务重新放回待执行池中，并结束执行。  
### 功能评价
相比于python的标准线程池库，本实现相对粗糙，但是可以更方便地对细节进行调整，以及可以自由实现相对复杂的分阶段调度策略。  
性能方面，标准库会在启动时创建固定数目的线程，之后的任务全部在这些线程中完成。而本实现无法做到这一点，依然需要为每个任务创建新的线程，并在完成后销毁当前线程。因此本实现虽然可以做到对并发度的控制，但是无法避免线程创建与销毁的开销。  


## Worker & Monitor
Monitor包含fetch和extend两个。  
Worker包含fetch, extend, add。其中add用于将文本数据添加到neo4j数据库中。因为不希望控制流过于复杂，所以将worker_add()设置为由另外两个Worker函数串行地调用，而不再进行单独的并发调度控制。  


## Assist
assist_clock()是总控函数，负责在特定时间调用另外两个Assist函数。  
assist_save()每小时执行一次，原则上是整点时。负责将当前各个池的状态写入文件作为记录，便于中断后恢复。  
assist_transport()每三小时执行一次，原则上是整点时被调用。负责将当前的多模态文件夹打包后传输到实验室集群上，以免VPS存储空间不足。为避免长时间阻塞extend任务，该函数首先将保存多模态的文件夹整体重命名，然后释放锁，并发地执行传输任务。  
